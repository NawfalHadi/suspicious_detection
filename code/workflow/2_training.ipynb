{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "023bac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a765161d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z73</th>\n",
       "      <th>v73</th>\n",
       "      <th>x74</th>\n",
       "      <th>y74</th>\n",
       "      <th>z74</th>\n",
       "      <th>v74</th>\n",
       "      <th>x75</th>\n",
       "      <th>y75</th>\n",
       "      <th>z75</th>\n",
       "      <th>v75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diam</td>\n",
       "      <td>0.543607</td>\n",
       "      <td>0.154529</td>\n",
       "      <td>-0.806512</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.549615</td>\n",
       "      <td>0.124989</td>\n",
       "      <td>-0.789710</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.514044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.771526</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>0.385645</td>\n",
       "      <td>0.659511</td>\n",
       "      <td>-0.477846</td>\n",
       "      <td>0.978621</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.577869</td>\n",
       "      <td>-0.231719</td>\n",
       "      <td>0.906865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diam</td>\n",
       "      <td>0.506170</td>\n",
       "      <td>0.182203</td>\n",
       "      <td>-0.680235</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.153888</td>\n",
       "      <td>-0.655531</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.477606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696684</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.345774</td>\n",
       "      <td>0.670790</td>\n",
       "      <td>-0.396579</td>\n",
       "      <td>0.979707</td>\n",
       "      <td>0.688755</td>\n",
       "      <td>0.615902</td>\n",
       "      <td>-0.268427</td>\n",
       "      <td>0.985749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diam</td>\n",
       "      <td>0.504694</td>\n",
       "      <td>0.167553</td>\n",
       "      <td>-0.766055</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.527472</td>\n",
       "      <td>0.134284</td>\n",
       "      <td>-0.739763</td>\n",
       "      <td>0.999921</td>\n",
       "      <td>0.475080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780847</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.352903</td>\n",
       "      <td>0.677664</td>\n",
       "      <td>-0.461034</td>\n",
       "      <td>0.982088</td>\n",
       "      <td>0.679477</td>\n",
       "      <td>0.620663</td>\n",
       "      <td>-0.349626</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x1        y1        z1        v1        x2        y2        z2  \\\n",
       "0  diam  0.543607  0.154529 -0.806512  0.999885  0.549615  0.124989 -0.789710   \n",
       "1  diam  0.506170  0.182203 -0.680235  0.999978  0.531654  0.153888 -0.655531   \n",
       "2  diam  0.504694  0.167553 -0.766055  0.999976  0.527472  0.134284 -0.739763   \n",
       "\n",
       "         v2        x3  ...       z73       v73       x74       y74       z74  \\\n",
       "0  0.999588  0.514044  ... -0.771526  0.999838  0.385645  0.659511 -0.477846   \n",
       "1  0.999925  0.477606  ... -0.696684  0.999917  0.345774  0.670790 -0.396579   \n",
       "2  0.999921  0.475080  ... -0.780847  0.999940  0.352903  0.677664 -0.461034   \n",
       "\n",
       "        v74       x75       y75       z75       v75  \n",
       "0  0.978621  0.663300  0.577869 -0.231719  0.906865  \n",
       "1  0.979707  0.688755  0.615902 -0.268427  0.985749  \n",
       "2  0.982088  0.679477  0.620663 -0.349626  0.985000  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/csv/dataset_v0.csv')\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2cd854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "diam        35\n",
       "celinguk    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0797f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 59\n",
      "Test set size: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46    celinguk\n",
       "57    celinguk\n",
       "33        diam\n",
       "36    celinguk\n",
       "6         diam\n",
       "25        diam\n",
       "63    celinguk\n",
       "66    celinguk\n",
       "8         diam\n",
       "20        diam\n",
       "29        diam\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1234)\n",
    "\n",
    "print(f\"Train set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fdaa2",
   "metadata": {},
   "source": [
    "# Training Model : LSTM SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9667ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and labels (y)\n",
    "X_raw = df.iloc[:, 1:].values\n",
    "y_raw = df['class'].values\n",
    "\n",
    "# Encode Labels (for multi-class classification)\n",
    "# Assuming 'diam' is just one class and there might be others in a full dataset\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y_raw)\n",
    "N_CLASSES = len(label_encoder.classes_)\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ae81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for LSTM (Single Timestep) ---\n",
    "# Format: [samples, timesteps, features]\n",
    "N_SAMPLES = X_scaled.shape[0]\n",
    "N_FEATURES_PER_SAMPLE = X_scaled.shape[1]\n",
    "N_TIMESTEPS = 1 # Each row is treated as one observation with one timestep\n",
    "\n",
    "X_reshaped = X_scaled.reshape(N_SAMPLES, N_TIMESTEPS, N_FEATURES_PER_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "621194ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_CLASSES > 2:\n",
    "    y_final = tf.keras.utils.to_categorical(y_encoded, num_classes=N_CLASSES)\n",
    "    loss_fn = 'categorical_crossentropy'\n",
    "    output_activation = 'softmax'\n",
    "else:\n",
    "    # If it's effectively binary (N_CLASSES=2), we still use sparse_categorical_crossentropy \n",
    "    # since we kept y_encoded as integer labels\n",
    "    y_final = y_encoded\n",
    "    loss_fn = 'sparse_categorical_crossentropy'\n",
    "    # If N_CLASSES=2, the Dense layer should have 1 unit with 'sigmoid' for binary_crossentropy\n",
    "    # or N_CLASSES units with 'softmax' for categorical_crossentropy. \n",
    "    # Since we use sparse_categorical_crossentropy with integer labels, N_CLASSES with 'softmax' is safest.\n",
    "    output_activation = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0008bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_reshaped, y_final, test_size=0.2, random_state=42, stratify=y_final\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbc0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761361810.788707   17507 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/mnt/c/users/nawfal/documents/apps/Collaborative_Project/suspicious_detection/.venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential([\n",
    "    # Single LSTM Layer (no return_sequences since it's the last recurrent layer)\n",
    "    LSTM(units=128, activation='relu', input_shape=(N_TIMESTEPS, N_FEATURES_PER_SAMPLE)),\n",
    "    Dropout(0.3),\n",
    "    # Output Dense layer\n",
    "    Dense(units=N_CLASSES, activation=output_activation)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "995731b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Input Shape: (1, 300)\n",
      "Model Output Classes: 2\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m219,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,906</span> (859.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m219,906\u001b[0m (859.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">219,906</span> (859.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m219,906\u001b[0m (859.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Starting Model Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 11:10:35.751577: I external/local_xla/xla/service/service.cc:163] XLA service 0x7477280d1830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-25 11:10:35.751703: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-10-25 11:10:35.922821: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-25 11:10:36.359296: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "I0000 00:00:1761361838.924534   20988 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\nModel Input Shape: {X_train.shape[1:]}\")\n",
    "print(f\"Model Output Classes: {N_CLASSES}\")\n",
    "print(\"-\" * 30)\n",
    "lstm_model.summary()\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Training (using the split training data)\n",
    "print(\"Starting Model Training...\")\n",
    "lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=4,\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Model Training Complete.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c97571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing artifacts (Scaler, Encoder) saved to: lstm_model_v0.pkl\n",
      "Trained Keras model weights saved to: single_lstm_weights_v0.keras\n",
      "\n",
      "To load and use this model, you'll need both files and the TensorFlow code to load the .keras file.\n"
     ]
    }
   ],
   "source": [
    "# Since TensorFlow models don't pickle reliably, we save the trained \n",
    "# Keras model separately and then pickle a dictionary containing the necessary \n",
    "# preprocessing objects.\n",
    "VERSION = 'v0'\n",
    "PICKLE_FILENAME = f'lstm_model_{VERSION}.pkl'\n",
    "KERAS_MODEL_FILENAME = f'single_lstm_weights_{VERSION}.keras'\n",
    "\n",
    "# 8a. Save the Keras model in its native format\n",
    "lstm_model.save(KERAS_MODEL_FILENAME)\n",
    "\n",
    "# 8b. Create a dictionary of necessary artifacts\n",
    "artifacts = {\n",
    "    'scaler': scaler,\n",
    "    'label_encoder': label_encoder,\n",
    "    'model_filename': KERAS_MODEL_FILENAME,\n",
    "    'input_shape': X_train.shape[1:],\n",
    "    'num_classes': N_CLASSES\n",
    "}\n",
    "\n",
    "# 8c. Pickle the artifacts dictionary\n",
    "with open(f'../../model/trained/{PICKLE_FILENAME}', 'wb') as file:\n",
    "    pickle.dump(artifacts, file)\n",
    "\n",
    "print(f\"Preprocessing artifacts (Scaler, Encoder) saved to: {PICKLE_FILENAME}\")\n",
    "print(f\"Trained Keras model weights saved to: {KERAS_MODEL_FILENAME}\")\n",
    "print(\"\\nTo load and use this model, you'll need both files and the TensorFlow code to load the .keras file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c68318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
